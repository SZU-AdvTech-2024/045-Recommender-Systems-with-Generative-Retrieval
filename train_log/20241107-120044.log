/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/transformers/utils/import_utils.py:455: FutureWarning: The util is_torch_bf16_available is deprecated, please use is_torch_bf16_gpu_available or is_torch_bf16_cpu_available instead according to whether it's used with cpu or gpu
  warnings.warn(
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-11-07 12:00:49,935 - INFO - hyper-param:
2024-11-07 12:00:49,935 - INFO -   output_dir: ./checkpoints
2024-11-07 12:00:49,935 - INFO -   batch_size: 128
2024-11-07 12:00:49,935 - INFO -   bf16: True
2024-11-07 12:00:49,935 - INFO -   epoch: 200
2024-11-07 12:00:49,935 - INFO -   optimizer: adamw_torch
2024-11-07 12:00:49,935 - INFO -   lr: 0.0005
2024-11-07 12:00:49,935 - INFO -   weight_decay: 0.01
2024-11-07 12:00:49,935 - INFO -   lr_scheduler_type: cosine
2024-11-07 12:00:49,935 - INFO -   warmup_ratio: 0.01
2024-11-07 12:00:49,935 - INFO -   gradient_accumulation_steps: 2
2024-11-07 12:00:49,935 - INFO -   plm_dir: ../LLM/
2024-11-07 12:00:49,935 - INFO -   plm_name: t5-base
2024-11-07 12:00:49,935 - INFO -   tokenizer_plm: sentence-t5-base
2024-11-07 12:00:49,935 - INFO -   dataset: Bili_Cartoon
2024-11-07 12:00:49,935 - INFO -   K: 256
2024-11-07 12:00:49,935 - INFO -   D: 4
2024-11-07 12:00:49,935 - INFO -   add_user_prefix: False
2024-11-07 12:00:49,935 - INFO -   user_prefix: <u_{}>
2024-11-07 12:00:49,935 - INFO -   item_sep: ,
2024-11-07 12:00:49,935 - INFO -   max_len: 20
2024-11-07 12:00:49,935 - INFO -   max_sent_len: 512
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-11-07 12:00:50,076 - WARNING - Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 4.427755832672119, 'eval_runtime': 33.5613, 'eval_samples_per_second': 902.826, 'eval_steps_per_second': 2.354, 'epoch': 0.9969230769230769}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 3.885916233062744, 'eval_runtime': 33.8112, 'eval_samples_per_second': 896.152, 'eval_steps_per_second': 2.337, 'epoch': 2.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 3.2570955753326416, 'eval_runtime': 33.5453, 'eval_samples_per_second': 903.257, 'eval_steps_per_second': 2.355, 'epoch': 2.996923076923077}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 4.744, 'grad_norm': 0.24593010544776917, 'learning_rate': 0.0004999628581159012, 'epoch': 3.076923076923077}
{'eval_loss': 2.826403856277466, 'eval_runtime': 33.9474, 'eval_samples_per_second': 892.557, 'eval_steps_per_second': 2.327, 'epoch': 4.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.534924030303955, 'eval_runtime': 33.5965, 'eval_samples_per_second': 901.878, 'eval_steps_per_second': 2.351, 'epoch': 4.996923076923077}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.4012012481689453, 'eval_runtime': 33.8823, 'eval_samples_per_second': 894.272, 'eval_steps_per_second': 2.332, 'epoch': 6.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.7661, 'grad_norm': 0.3727874159812927, 'learning_rate': 0.0004994522478556245, 'epoch': 6.153846153846154}
{'eval_loss': 2.2667038440704346, 'eval_runtime': 33.8113, 'eval_samples_per_second': 896.15, 'eval_steps_per_second': 2.336, 'epoch': 6.996923076923077}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.222468614578247, 'eval_runtime': 34.151, 'eval_samples_per_second': 887.237, 'eval_steps_per_second': 2.313, 'epoch': 8.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.166306734085083, 'eval_runtime': 34.1614, 'eval_samples_per_second': 886.965, 'eval_steps_per_second': 2.313, 'epoch': 8.996923076923077}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.2271, 'grad_norm': 0.44078394770622253, 'learning_rate': 0.0004983435290987227, 'epoch': 9.23076923076923}
{'eval_loss': 2.1530699729919434, 'eval_runtime': 36.8722, 'eval_samples_per_second': 821.757, 'eval_steps_per_second': 2.143, 'epoch': 10.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.1033332347869873, 'eval_runtime': 36.8135, 'eval_samples_per_second': 823.067, 'eval_steps_per_second': 2.146, 'epoch': 10.996923076923077}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.0833802223205566, 'eval_runtime': 36.9465, 'eval_samples_per_second': 820.106, 'eval_steps_per_second': 2.138, 'epoch': 12.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.0745, 'grad_norm': 0.28506940603256226, 'learning_rate': 0.0004966393602061228, 'epoch': 12.307692307692308}
{'eval_loss': 2.0684685707092285, 'eval_runtime': 36.0691, 'eval_samples_per_second': 840.054, 'eval_steps_per_second': 2.19, 'epoch': 12.996923076923077}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.0636703968048096, 'eval_runtime': 36.7365, 'eval_samples_per_second': 824.793, 'eval_steps_per_second': 2.15, 'epoch': 14.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.0399553775787354, 'eval_runtime': 35.796, 'eval_samples_per_second': 846.463, 'eval_steps_per_second': 2.207, 'epoch': 14.996923076923077}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.0043, 'grad_norm': 0.2603720426559448, 'learning_rate': 0.0004943438272420042, 'epoch': 15.384615384615385}
{'eval_loss': 2.0234744548797607, 'eval_runtime': 33.5212, 'eval_samples_per_second': 903.907, 'eval_steps_per_second': 2.357, 'epoch': 16.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.010225534439087, 'eval_runtime': 33.5982, 'eval_samples_per_second': 901.833, 'eval_steps_per_second': 2.351, 'epoch': 16.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.009669542312622, 'eval_runtime': 33.9032, 'eval_samples_per_second': 893.72, 'eval_steps_per_second': 2.33, 'epoch': 18.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.9595, 'grad_norm': 0.15687622129917145, 'learning_rate': 0.0004914624341766933, 'epoch': 18.46153846153846}
{'eval_loss': 1.9890810251235962, 'eval_runtime': 33.6732, 'eval_samples_per_second': 899.826, 'eval_steps_per_second': 2.346, 'epoch': 18.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.973814845085144, 'eval_runtime': 33.8328, 'eval_samples_per_second': 895.58, 'eval_steps_per_second': 2.335, 'epoch': 20.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.963802456855774, 'eval_runtime': 34.5146, 'eval_samples_per_second': 877.888, 'eval_steps_per_second': 2.289, 'epoch': 20.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.92, 'grad_norm': 0.35993698239326477, 'learning_rate': 0.0004880020896898646, 'epoch': 21.53846153846154}
{'eval_loss': 1.951367735862732, 'eval_runtime': 34.3661, 'eval_samples_per_second': 881.682, 'eval_steps_per_second': 2.299, 'epoch': 22.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.93556547164917, 'eval_runtime': 33.9495, 'eval_samples_per_second': 892.503, 'eval_steps_per_second': 2.327, 'epoch': 22.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.9328200817108154, 'eval_runtime': 34.5278, 'eval_samples_per_second': 877.555, 'eval_steps_per_second': 2.288, 'epoch': 24.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.8791, 'grad_norm': 0.15380313992500305, 'learning_rate': 0.0004839710906056861, 'epoch': 24.615384615384617}
{'eval_loss': 1.9169466495513916, 'eval_runtime': 34.6255, 'eval_samples_per_second': 875.078, 'eval_steps_per_second': 2.282, 'epoch': 24.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.9175548553466797, 'eval_runtime': 34.2786, 'eval_samples_per_second': 883.933, 'eval_steps_per_second': 2.305, 'epoch': 26.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.9097251892089844, 'eval_runtime': 34.9399, 'eval_samples_per_second': 867.204, 'eval_steps_per_second': 2.261, 'epoch': 26.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.8459, 'grad_norm': 0.35391291975975037, 'learning_rate': 0.00047937910199962987, 'epoch': 27.692307692307693}
{'eval_loss': 1.8961375951766968, 'eval_runtime': 34.2287, 'eval_samples_per_second': 885.221, 'eval_steps_per_second': 2.308, 'epoch': 28.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.8792833089828491, 'eval_runtime': 34.3572, 'eval_samples_per_second': 881.911, 'eval_steps_per_second': 2.299, 'epoch': 28.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.8705768585205078, 'eval_runtime': 34.41, 'eval_samples_per_second': 880.557, 'eval_steps_per_second': 2.296, 'epoch': 30.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.8084, 'grad_norm': 0.27717292308807373, 'learning_rate': 0.00047423713402464204, 'epoch': 30.76923076923077}
{'eval_loss': 1.8422660827636719, 'eval_runtime': 34.3095, 'eval_samples_per_second': 883.137, 'eval_steps_per_second': 2.303, 'epoch': 30.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.8224327564239502, 'eval_runtime': 34.2572, 'eval_samples_per_second': 884.486, 'eval_steps_per_second': 2.306, 'epoch': 32.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.8052066564559937, 'eval_runtime': 34.0298, 'eval_samples_per_second': 890.397, 'eval_steps_per_second': 2.321, 'epoch': 32.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.7496, 'grad_norm': 0.54099440574646, 'learning_rate': 0.000468557515512239, 'epoch': 33.84615384615385}
{'eval_loss': 1.777815818786621, 'eval_runtime': 36.3869, 'eval_samples_per_second': 832.717, 'eval_steps_per_second': 2.171, 'epoch': 34.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.749304175376892, 'eval_runtime': 36.2683, 'eval_samples_per_second': 835.441, 'eval_steps_per_second': 2.178, 'epoch': 34.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.7274621725082397, 'eval_runtime': 34.3363, 'eval_samples_per_second': 882.448, 'eval_steps_per_second': 2.301, 'epoch': 36.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.6719, 'grad_norm': 0.19797295331954956, 'learning_rate': 0.0004623538644118244, 'epoch': 36.92307692307692}
{'eval_loss': 1.7045259475708008, 'eval_runtime': 34.2936, 'eval_samples_per_second': 883.546, 'eval_steps_per_second': 2.304, 'epoch': 36.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.681938886642456, 'eval_runtime': 34.5455, 'eval_samples_per_second': 877.104, 'eval_steps_per_second': 2.287, 'epoch': 38.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6706886291503906, 'eval_runtime': 34.682, 'eval_samples_per_second': 873.653, 'eval_steps_per_second': 2.278, 'epoch': 38.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5946, 'grad_norm': 0.2847791612148285, 'learning_rate': 0.00045564105513910336, 'epoch': 40.0}
{'eval_loss': 1.6458895206451416, 'eval_runtime': 34.2231, 'eval_samples_per_second': 885.366, 'eval_steps_per_second': 2.308, 'epoch': 40.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6381279230117798, 'eval_runtime': 34.1565, 'eval_samples_per_second': 887.092, 'eval_steps_per_second': 2.313, 'epoch': 40.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6262810230255127, 'eval_runtime': 34.1829, 'eval_samples_per_second': 886.409, 'eval_steps_per_second': 2.311, 'epoch': 42.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6112027168273926, 'eval_runtime': 34.478, 'eval_samples_per_second': 878.822, 'eval_steps_per_second': 2.291, 'epoch': 42.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5327, 'grad_norm': 0.16032461822032928, 'learning_rate': 0.00044843518291188525, 'epoch': 43.07692307692308}
{'eval_loss': 1.59873366355896, 'eval_runtime': 34.0725, 'eval_samples_per_second': 889.281, 'eval_steps_per_second': 2.319, 'epoch': 44.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.59452486038208, 'eval_runtime': 34.2199, 'eval_samples_per_second': 885.45, 'eval_steps_per_second': 2.309, 'epoch': 44.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5925524234771729, 'eval_runtime': 34.3716, 'eval_samples_per_second': 881.542, 'eval_steps_per_second': 2.298, 'epoch': 46.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.4876, 'grad_norm': 0.15908175706863403, 'learning_rate': 0.00044075352515878316, 'epoch': 46.15384615384615}
{'eval_loss': 1.5815379619598389, 'eval_runtime': 34.2989, 'eval_samples_per_second': 883.409, 'eval_steps_per_second': 2.303, 'epoch': 46.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5770742893218994, 'eval_runtime': 34.1479, 'eval_samples_per_second': 887.317, 'eval_steps_per_second': 2.313, 'epoch': 48.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5724295377731323, 'eval_runtime': 34.0195, 'eval_samples_per_second': 890.666, 'eval_steps_per_second': 2.322, 'epoch': 48.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.4524, 'grad_norm': 0.30877962708473206, 'learning_rate': 0.000432614500093342, 'epoch': 49.23076923076923}
{'eval_loss': 1.5639625787734985, 'eval_runtime': 34.2091, 'eval_samples_per_second': 885.729, 'eval_steps_per_second': 2.309, 'epoch': 50.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5678499937057495, 'eval_runtime': 34.0923, 'eval_samples_per_second': 888.764, 'eval_steps_per_second': 2.317, 'epoch': 50.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.569586992263794, 'eval_runtime': 34.2359, 'eval_samples_per_second': 885.035, 'eval_steps_per_second': 2.308, 'epoch': 52.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.426, 'grad_norm': 0.2682211101055145, 'learning_rate': 0.00042403762255292153, 'epoch': 52.30769230769231}
{'eval_loss': 1.5552618503570557, 'eval_runtime': 34.4713, 'eval_samples_per_second': 878.992, 'eval_steps_per_second': 2.292, 'epoch': 52.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5563359260559082, 'eval_runtime': 34.1209, 'eval_samples_per_second': 888.019, 'eval_steps_per_second': 2.315, 'epoch': 54.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5552784204483032, 'eval_runtime': 34.0804, 'eval_samples_per_second': 889.074, 'eval_steps_per_second': 2.318, 'epoch': 54.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.4015, 'grad_norm': 0.1599433720111847, 'learning_rate': 0.0004150434572082173, 'epoch': 55.38461538461539}
{'eval_loss': 1.5562413930892944, 'eval_runtime': 33.9706, 'eval_samples_per_second': 891.948, 'eval_steps_per_second': 2.326, 'epoch': 56.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5576146841049194, 'eval_runtime': 34.1278, 'eval_samples_per_second': 887.84, 'eval_steps_per_second': 2.315, 'epoch': 56.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.550044059753418, 'eval_runtime': 33.8854, 'eval_samples_per_second': 894.189, 'eval_steps_per_second': 2.331, 'epoch': 58.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.3786, 'grad_norm': 0.22891032695770264, 'learning_rate': 0.0004056535692556104, 'epoch': 58.46153846153846}
{'eval_loss': 1.5562994480133057, 'eval_runtime': 34.6614, 'eval_samples_per_second': 874.172, 'eval_steps_per_second': 2.279, 'epoch': 58.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5558857917785645, 'eval_runtime': 34.167, 'eval_samples_per_second': 886.82, 'eval_steps_per_second': 2.312, 'epoch': 60.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.555917739868164, 'eval_runtime': 34.163, 'eval_samples_per_second': 886.925, 'eval_steps_per_second': 2.312, 'epoch': 60.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.3559, 'grad_norm': 0.2295292615890503, 'learning_rate': 0.0003958904727105691, 'epoch': 61.53846153846154}
{'eval_loss': 1.5599329471588135, 'eval_runtime': 37.2104, 'eval_samples_per_second': 814.289, 'eval_steps_per_second': 2.123, 'epoch': 62.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5522056818008423, 'eval_runtime': 37.079, 'eval_samples_per_second': 817.175, 'eval_steps_per_second': 2.131, 'epoch': 62.996923076923075}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5560321807861328, 'eval_runtime': 36.9128, 'eval_samples_per_second': 820.854, 'eval_steps_per_second': 2.14, 'epoch': 64.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.3344, 'grad_norm': 0.20944248139858246, 'learning_rate': 0.0003857775764260789, 'epoch': 64.61538461538461}
{'eval_loss': 1.5595884323120117, 'eval_runtime': 37.0937, 'eval_samples_per_second': 816.849, 'eval_steps_per_second': 2.13, 'epoch': 64.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.562771201133728, 'eval_runtime': 36.9726, 'eval_samples_per_second': 819.525, 'eval_steps_per_second': 2.137, 'epoch': 66.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5627317428588867, 'eval_runtime': 36.8833, 'eval_samples_per_second': 821.511, 'eval_steps_per_second': 2.142, 'epoch': 66.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.3112, 'grad_norm': 0.32499346137046814, 'learning_rate': 0.0003753391279655322, 'epoch': 67.6923076923077}
{'eval_loss': 1.5708777904510498, 'eval_runtime': 36.8968, 'eval_samples_per_second': 821.21, 'eval_steps_per_second': 2.141, 'epoch': 68.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.575767159461975, 'eval_runtime': 36.6341, 'eval_samples_per_second': 827.098, 'eval_steps_per_second': 2.156, 'epoch': 68.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5747283697128296, 'eval_runtime': 36.9315, 'eval_samples_per_second': 820.439, 'eval_steps_per_second': 2.139, 'epoch': 70.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.2879, 'grad_norm': 0.3522546887397766, 'learning_rate': 0.00036460015546465235, 'epoch': 70.76923076923077}
{'eval_loss': 1.5777896642684937, 'eval_runtime': 36.9999, 'eval_samples_per_second': 818.922, 'eval_steps_per_second': 2.135, 'epoch': 70.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.589337944984436, 'eval_runtime': 36.8316, 'eval_samples_per_second': 822.663, 'eval_steps_per_second': 2.145, 'epoch': 72.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5911593437194824, 'eval_runtime': 36.7584, 'eval_samples_per_second': 824.302, 'eval_steps_per_second': 2.149, 'epoch': 72.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.2642, 'grad_norm': 0.33996304869651794, 'learning_rate': 0.00035358640762184966, 'epoch': 73.84615384615384}
{'eval_loss': 1.5932960510253906, 'eval_runtime': 37.0409, 'eval_samples_per_second': 818.016, 'eval_steps_per_second': 2.133, 'epoch': 74.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5976232290267944, 'eval_runtime': 37.3665, 'eval_samples_per_second': 810.887, 'eval_steps_per_second': 2.114, 'epoch': 74.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.5988280773162842, 'eval_runtime': 36.8199, 'eval_samples_per_second': 822.925, 'eval_steps_per_second': 2.146, 'epoch': 76.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.2405, 'grad_norm': 0.32969674468040466, 'learning_rate': 0.00034232429196089304, 'epoch': 76.92307692307692}
{'eval_loss': 1.6102162599563599, 'eval_runtime': 37.0925, 'eval_samples_per_second': 816.877, 'eval_steps_per_second': 2.13, 'epoch': 76.99692307692308}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6199383735656738, 'eval_runtime': 36.9211, 'eval_samples_per_second': 820.669, 'eval_steps_per_second': 2.14, 'epoch': 78.0}
There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].
{'train_runtime': 30208.5452, 'train_samples_per_second': 824.555, 'train_steps_per_second': 1.073, 'train_loss': 1.7809294631025026, 'epoch': 78.0}
