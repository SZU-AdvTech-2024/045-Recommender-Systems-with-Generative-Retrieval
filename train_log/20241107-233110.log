/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/transformers/utils/import_utils.py:455: FutureWarning: The util is_torch_bf16_available is deprecated, please use is_torch_bf16_gpu_available or is_torch_bf16_cpu_available instead according to whether it's used with cpu or gpu
  warnings.warn(
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-11-07 23:31:24,699 - INFO - hyper-param:
2024-11-07 23:31:24,699 - INFO -   output_dir: ./checkpoints
2024-11-07 23:31:24,699 - INFO -   batch_size: 128
2024-11-07 23:31:24,699 - INFO -   bf16: True
2024-11-07 23:31:24,699 - INFO -   epoch: 200
2024-11-07 23:31:24,699 - INFO -   optimizer: adamw_torch
2024-11-07 23:31:24,699 - INFO -   lr: 0.0005
2024-11-07 23:31:24,699 - INFO -   weight_decay: 0.01
2024-11-07 23:31:24,699 - INFO -   lr_scheduler_type: cosine
2024-11-07 23:31:24,700 - INFO -   warmup_ratio: 0.01
2024-11-07 23:31:24,700 - INFO -   gradient_accumulation_steps: 2
2024-11-07 23:31:24,700 - INFO -   plm_dir: ../LLM/
2024-11-07 23:31:24,700 - INFO -   plm_name: t5-base
2024-11-07 23:31:24,700 - INFO -   tokenizer_plm: sentence-t5-base
2024-11-07 23:31:24,700 - INFO -   dataset: Games
2024-11-07 23:31:24,700 - INFO -   K: 256
2024-11-07 23:31:24,700 - INFO -   D: 4
2024-11-07 23:31:24,700 - INFO -   add_user_prefix: False
2024-11-07 23:31:24,700 - INFO -   user_prefix: <u_{}>
2024-11-07 23:31:24,700 - INFO -   item_sep: ,
2024-11-07 23:31:24,700 - INFO -   max_len: 20
2024-11-07 23:31:24,700 - INFO -   max_sent_len: 512
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
2024-11-07 23:31:25,034 - WARNING - Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 5.270105838775635, 'eval_runtime': 60.2664, 'eval_samples_per_second': 838.709, 'eval_steps_per_second': 2.19, 'epoch': 0.9987261146496815}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 5.8843, 'grad_norm': 1.2366364002227783, 'learning_rate': 0.00031887755102040814, 'epoch': 1.2738853503184713}
{'eval_loss': 4.8058552742004395, 'eval_runtime': 60.8153, 'eval_samples_per_second': 831.14, 'eval_steps_per_second': 2.171, 'epoch': 2.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 4.9146, 'grad_norm': 0.29198122024536133, 'learning_rate': 0.0004999904454116691, 'epoch': 2.5477707006369426}
{'eval_loss': 3.71136474609375, 'eval_runtime': 60.4581, 'eval_samples_per_second': 836.05, 'eval_steps_per_second': 2.183, 'epoch': 2.9987261146496813}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 3.8888, 'grad_norm': 0.30028682947158813, 'learning_rate': 0.0004998950208887939, 'epoch': 3.821656050955414}
{'eval_loss': 3.06569242477417, 'eval_runtime': 59.3678, 'eval_samples_per_second': 851.405, 'eval_steps_per_second': 2.223, 'epoch': 4.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.72666072845459, 'eval_runtime': 59.388, 'eval_samples_per_second': 851.115, 'eval_steps_per_second': 2.223, 'epoch': 4.998726114649681}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 3.24, 'grad_norm': 1.2614532709121704, 'learning_rate': 0.0004996972482106574, 'epoch': 5.095541401273885}
{'eval_loss': 2.5255420207977295, 'eval_runtime': 59.8169, 'eval_samples_per_second': 845.013, 'eval_steps_per_second': 2.207, 'epoch': 6.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.8894, 'grad_norm': 0.3383446931838989, 'learning_rate': 0.0004993972083779482, 'epoch': 6.369426751592357}
{'eval_loss': 2.3853602409362793, 'eval_runtime': 59.8411, 'eval_samples_per_second': 844.671, 'eval_steps_per_second': 2.206, 'epoch': 6.998726114649681}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.6678, 'grad_norm': 0.4686337411403656, 'learning_rate': 0.0004989950242763614, 'epoch': 7.643312101910828}
{'eval_loss': 2.2850282192230225, 'eval_runtime': 59.7171, 'eval_samples_per_second': 846.424, 'eval_steps_per_second': 2.21, 'epoch': 8.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.5072, 'grad_norm': 0.39824265241622925, 'learning_rate': 0.0004984908606262696, 'epoch': 8.9171974522293}
{'eval_loss': 2.197662115097046, 'eval_runtime': 59.8177, 'eval_samples_per_second': 845.001, 'eval_steps_per_second': 2.207, 'epoch': 8.998726114649681}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 2.1079089641571045, 'eval_runtime': 59.1523, 'eval_samples_per_second': 854.506, 'eval_steps_per_second': 2.232, 'epoch': 10.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.3792, 'grad_norm': 0.3665250837802887, 'learning_rate': 0.0004978849239152582, 'epoch': 10.19108280254777}
{'eval_loss': 2.0375242233276367, 'eval_runtime': 59.049, 'eval_samples_per_second': 856.001, 'eval_steps_per_second': 2.235, 'epoch': 10.998726114649681}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.267, 'grad_norm': 0.3321346342563629, 'learning_rate': 0.0004971774623135563, 'epoch': 11.464968152866241}
{'eval_loss': 1.9793237447738647, 'eval_runtime': 59.1021, 'eval_samples_per_second': 855.232, 'eval_steps_per_second': 2.233, 'epoch': 12.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.1715, 'grad_norm': 0.3545292913913727, 'learning_rate': 0.0004963687655723947, 'epoch': 12.738853503184714}
{'eval_loss': 1.9270488023757935, 'eval_runtime': 59.7085, 'eval_samples_per_second': 846.546, 'eval_steps_per_second': 2.211, 'epoch': 12.998726114649681}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.875597596168518, 'eval_runtime': 59.681, 'eval_samples_per_second': 846.936, 'eval_steps_per_second': 2.212, 'epoch': 14.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.091, 'grad_norm': 0.3088914453983307, 'learning_rate': 0.0004954591649053339, 'epoch': 14.012738853503185}
{'eval_loss': 1.8461335897445679, 'eval_runtime': 59.7028, 'eval_samples_per_second': 846.628, 'eval_steps_per_second': 2.211, 'epoch': 14.998726114649681}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 2.0229, 'grad_norm': 0.30726358294487, 'learning_rate': 0.0004944490328526109, 'epoch': 15.286624203821656}
{'eval_loss': 1.817805290222168, 'eval_runtime': 59.974, 'eval_samples_per_second': 842.799, 'eval_steps_per_second': 2.201, 'epoch': 16.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.9716, 'grad_norm': 0.3013763725757599, 'learning_rate': 0.0004933387831285597, 'epoch': 16.56050955414013}
{'eval_loss': 1.7953802347183228, 'eval_runtime': 59.937, 'eval_samples_per_second': 843.318, 'eval_steps_per_second': 2.202, 'epoch': 16.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.9235, 'grad_norm': 0.4022367000579834, 'learning_rate': 0.0004921288704521689, 'epoch': 17.8343949044586}
{'eval_loss': 1.7655128240585327, 'eval_runtime': 59.7666, 'eval_samples_per_second': 845.724, 'eval_steps_per_second': 2.209, 'epoch': 18.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.7536035776138306, 'eval_runtime': 59.898, 'eval_samples_per_second': 843.868, 'eval_steps_per_second': 2.204, 'epoch': 18.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.8846, 'grad_norm': 0.31484663486480713, 'learning_rate': 0.0004908197903608448, 'epoch': 19.10828025477707}
{'eval_loss': 1.7366174459457397, 'eval_runtime': 59.1798, 'eval_samples_per_second': 854.109, 'eval_steps_per_second': 2.23, 'epoch': 20.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.8494, 'grad_norm': 0.31408244371414185, 'learning_rate': 0.0004894120790074561, 'epoch': 20.38216560509554}
{'eval_loss': 1.7191176414489746, 'eval_runtime': 59.2203, 'eval_samples_per_second': 853.526, 'eval_steps_per_second': 2.229, 'epoch': 20.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.8212, 'grad_norm': 0.242171511054039, 'learning_rate': 0.0004879063129407462, 'epoch': 21.656050955414013}
{'eval_loss': 1.7048143148422241, 'eval_runtime': 59.7784, 'eval_samples_per_second': 845.556, 'eval_steps_per_second': 2.208, 'epoch': 22.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.7968, 'grad_norm': 0.2927435338497162, 'learning_rate': 0.0004863031088691977, 'epoch': 22.929936305732483}
{'eval_loss': 1.6958588361740112, 'eval_runtime': 59.1103, 'eval_samples_per_second': 855.113, 'eval_steps_per_second': 2.233, 'epoch': 22.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.684340476989746, 'eval_runtime': 59.3192, 'eval_samples_per_second': 852.102, 'eval_steps_per_second': 2.225, 'epoch': 24.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.7687, 'grad_norm': 0.3546140789985657, 'learning_rate': 0.00048460312340845116, 'epoch': 24.203821656050955}
{'eval_loss': 1.6703611612319946, 'eval_runtime': 58.9896, 'eval_samples_per_second': 856.862, 'eval_steps_per_second': 2.238, 'epoch': 24.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.7469, 'grad_norm': 0.4434892237186432, 'learning_rate': 0.0004828070528123786, 'epoch': 25.477707006369428}
{'eval_loss': 1.666465401649475, 'eval_runtime': 58.9158, 'eval_samples_per_second': 857.937, 'eval_steps_per_second': 2.24, 'epoch': 26.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.7271, 'grad_norm': 0.25824660062789917, 'learning_rate': 0.00048091563268792234, 'epoch': 26.751592356687897}
{'eval_loss': 1.6588138341903687, 'eval_runtime': 59.7113, 'eval_samples_per_second': 846.507, 'eval_steps_per_second': 2.211, 'epoch': 26.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6568818092346191, 'eval_runtime': 60.384, 'eval_samples_per_second': 837.076, 'eval_steps_per_second': 2.186, 'epoch': 28.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.708, 'grad_norm': 0.28465205430984497, 'learning_rate': 0.0004789296376938166, 'epoch': 28.02547770700637}
{'eval_loss': 1.6504231691360474, 'eval_runtime': 61.577, 'eval_samples_per_second': 820.858, 'eval_steps_per_second': 2.144, 'epoch': 28.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.6864, 'grad_norm': 0.3317774534225464, 'learning_rate': 0.00047684988122331464, 'epoch': 29.29936305732484}
{'eval_loss': 1.6429895162582397, 'eval_runtime': 60.852, 'eval_samples_per_second': 830.638, 'eval_steps_per_second': 2.169, 'epoch': 30.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.6702, 'grad_norm': 0.34663841128349304, 'learning_rate': 0.0004746772150710516, 'epoch': 30.573248407643312}
{'eval_loss': 1.638546109199524, 'eval_runtime': 60.5891, 'eval_samples_per_second': 834.242, 'eval_steps_per_second': 2.179, 'epoch': 30.99872611464968}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.6536, 'grad_norm': 0.355538547039032, 'learning_rate': 0.00047241252908417964, 'epoch': 31.847133757961785}
{'eval_loss': 1.632803201675415, 'eval_runtime': 60.9756, 'eval_samples_per_second': 828.955, 'eval_steps_per_second': 2.165, 'epoch': 32.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6290256977081299, 'eval_runtime': 60.1786, 'eval_samples_per_second': 839.934, 'eval_steps_per_second': 2.193, 'epoch': 32.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.6377, 'grad_norm': 0.33437851071357727, 'learning_rate': 0.0004700567507979181, 'epoch': 33.12101910828026}
{'eval_loss': 1.628892421722412, 'eval_runtime': 60.6367, 'eval_samples_per_second': 833.588, 'eval_steps_per_second': 2.177, 'epoch': 34.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.6208, 'grad_norm': 0.29082396626472473, 'learning_rate': 0.00046761084505566783, 'epoch': 34.394904458598724}
{'eval_loss': 1.626869559288025, 'eval_runtime': 61.276, 'eval_samples_per_second': 824.89, 'eval_steps_per_second': 2.154, 'epoch': 34.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.6039, 'grad_norm': 0.2358713448047638, 'learning_rate': 0.00046507581361384537, 'epoch': 35.6687898089172}
{'eval_loss': 1.6277518272399902, 'eval_runtime': 61.3145, 'eval_samples_per_second': 824.372, 'eval_steps_per_second': 2.153, 'epoch': 36.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5899, 'grad_norm': 0.3843132257461548, 'learning_rate': 0.00046245269473159937, 'epoch': 36.94267515923567}
{'eval_loss': 1.6240582466125488, 'eval_runtime': 60.8406, 'eval_samples_per_second': 830.794, 'eval_steps_per_second': 2.17, 'epoch': 36.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.628059983253479, 'eval_runtime': 61.0459, 'eval_samples_per_second': 828.0, 'eval_steps_per_second': 2.162, 'epoch': 38.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5722, 'grad_norm': 0.32154470682144165, 'learning_rate': 0.00045974256274557574, 'epoch': 38.21656050955414}
{'eval_loss': 1.6222319602966309, 'eval_runtime': 60.8396, 'eval_samples_per_second': 830.808, 'eval_steps_per_second': 2.17, 'epoch': 38.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5558, 'grad_norm': 0.2556025981903076, 'learning_rate': 0.0004569465276299082, 'epoch': 39.49044585987261}
{'eval_loss': 1.6246178150177002, 'eval_runtime': 61.5454, 'eval_samples_per_second': 821.28, 'eval_steps_per_second': 2.145, 'epoch': 40.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5425, 'grad_norm': 0.2786000669002533, 'learning_rate': 0.0004540657345416115, 'epoch': 40.76433121019108}
{'eval_loss': 1.6235657930374146, 'eval_runtime': 55.5539, 'eval_samples_per_second': 909.855, 'eval_steps_per_second': 2.376, 'epoch': 40.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6306451559066772, 'eval_runtime': 56.6682, 'eval_samples_per_second': 891.964, 'eval_steps_per_second': 2.329, 'epoch': 42.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5268, 'grad_norm': 0.3113747239112854, 'learning_rate': 0.00045110136335156593, 'epoch': 42.038216560509554}
{'eval_loss': 1.6280848979949951, 'eval_runtime': 56.1401, 'eval_samples_per_second': 900.355, 'eval_steps_per_second': 2.351, 'epoch': 42.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.5095, 'grad_norm': 0.31533685326576233, 'learning_rate': 0.0004480546281612838, 'epoch': 43.31210191082803}
{'eval_loss': 1.6328765153884888, 'eval_runtime': 56.0664, 'eval_samples_per_second': 901.538, 'eval_steps_per_second': 2.354, 'epoch': 44.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.4961, 'grad_norm': 0.3641343414783478, 'learning_rate': 0.00044492677680565696, 'epoch': 44.5859872611465}
{'eval_loss': 1.624951720237732, 'eval_runtime': 59.3312, 'eval_samples_per_second': 851.929, 'eval_steps_per_second': 2.225, 'epoch': 44.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.4816, 'grad_norm': 0.30001360177993774, 'learning_rate': 0.00044171909034188694, 'epoch': 45.859872611464965}
{'eval_loss': 1.6377320289611816, 'eval_runtime': 55.4981, 'eval_samples_per_second': 910.77, 'eval_steps_per_second': 2.378, 'epoch': 46.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'eval_loss': 1.6436326503753662, 'eval_runtime': 56.2416, 'eval_samples_per_second': 898.73, 'eval_steps_per_second': 2.347, 'epoch': 46.998726114649685}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.4633, 'grad_norm': 0.4106876850128174, 'learning_rate': 0.00043843288252480984, 'epoch': 47.13375796178344}
{'eval_loss': 1.646738886833191, 'eval_runtime': 55.5998, 'eval_samples_per_second': 909.105, 'eval_steps_per_second': 2.374, 'epoch': 48.0}
/home/hcw/miniconda3/envs/pytorch_lqx/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
{'loss': 1.4491, 'grad_norm': 0.33527323603630066, 'learning_rate': 0.00043506949926882887, 'epoch': 48.40764331210191}
{'eval_loss': 1.6528360843658447, 'eval_runtime': 55.9269, 'eval_samples_per_second': 903.786, 'eval_steps_per_second': 2.36, 'epoch': 48.998726114649685}
There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].
{'train_runtime': 44836.5142, 'train_samples_per_second': 1344.221, 'train_steps_per_second': 1.749, 'train_loss': 2.102045010012914, 'epoch': 48.998726114649685}
